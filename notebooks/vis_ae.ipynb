{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.settings import *\n",
    "import pickle as pkl\n",
    "import gzip\n",
    "from src.tools.vis_utils import VisualizationConfig, FIGSIZE, visualize_dendrogram, plot_hexagons_map, plot_clusters, ensure_geometry_type\n",
    "from src.tools.dim_reduction import reduce_tsne\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import dataclasses\n",
    "import json5 as json\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "from src.tools.configs import ExperimentConfig\n",
    "from src.tools.clustering import remap_cluster\n",
    "from src.tools.feature_extraction import features_wide_to_long\n",
    "from sklearn.metrics import pairwise_distances, pairwise_distances_argmin\n",
    "from tqdm.auto import tqdm\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import contextily as ctx\n",
    "import operator\n",
    "from src.tools.vis_utils import visualize_kepler, save_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"run_01\"\n",
    "run_dir = RUNS_DATA_DIR / run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / \"experiment_config.json\", \"r\") as f:\n",
    "    ec_json = json.load(f)\n",
    "    ec = ExperimentConfig(**ec_json)\n",
    "ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VisualizationConfig(\n",
    "    n_clusters=None,\n",
    "    distance_threshold=0,\n",
    "    affinity=\"euclidean\",\n",
    "    linkage=\"ward\",\n",
    "    truncate_mode=\"level\",\n",
    "    p=3,\n",
    "    clusters=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    cities_to_plot=[\"Wrocław\", \"Kraków\"],\n",
    "    countries_subsample=[\"Poland\", \"Germany\"],\n",
    "    umap_n_components=2,\n",
    "    umap_n_neighbours=30,\n",
    "    umap_metric=\"euclidean\",\n",
    "    tsne_perplexity=100,\n",
    ")\n",
    "\n",
    "vis_dir = run_dir / \"vis\"\n",
    "vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(vis_dir / \"vis_config.json\", \"w\") as f:\n",
    "    json.dump(dataclasses.asdict(vc), f, indent=2, quote_keys=True, trailing_commas=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(run_dir / \"dataset.pkl.gz\", \"rb\") as f:\n",
    "    ds = pkl.load(f)\n",
    "\n",
    "z_df = pd.read_pickle(run_dir / \"embeddings.pkl.gz\")\n",
    "input_df = pd.read_pickle(run_dir / \"input.pkl.gz\")\n",
    "\n",
    "if ec.mode == \"edges\":\n",
    "    z_df_edges = z_df\n",
    "    z_df = z_df.groupby(level=[0, 1, 2, 3]).mean()\n",
    "\n",
    "    input_df_edges = input_df\n",
    "    input_df = input_df.groupby(level=[0, 1, 2, 3]).sum()\n",
    "    input_df_mean = input_df_edges.groupby(level=[0, 1, 2, 3]).mean()\n",
    "\n",
    "z_df_scaled = pd.DataFrame(StandardScaler().fit_transform(z_df), index=z_df.index, columns=z_df.columns)\n",
    "z_df_scaled_cosine = pd.DataFrame(StandardScaler(with_std=False).fit_transform(z_df), index=z_df.index, columns=z_df.columns)\n",
    "hexagons = ds.hexagons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_subsample = vc.countries_subsample\n",
    "\n",
    "z_df = z_df.loc[(slice(None), countries_subsample), :]\n",
    "z_df_scaled = z_df_scaled.loc[(slice(None), countries_subsample), :]\n",
    "z_df_scaled_cosine = z_df_scaled_cosine.loc[(slice(None), countries_subsample), :]\n",
    "z_df_edges = z_df_edges.loc[(slice(None), countries_subsample), :]\n",
    "ds.edges = ds.edges.loc[(slice(None), countries_subsample), :]\n",
    "ds.edges_feature_selected = ds.edges_feature_selected.loc[(slice(None), countries_subsample), :]\n",
    "input_df = input_df.loc[(slice(None), countries_subsample), :]\n",
    "input_df_edges = input_df_edges.loc[(slice(None), countries_subsample), :]\n",
    "input_df_mean = input_df_mean.loc[(slice(None), countries_subsample), :]\n",
    "ds.hexagons = ds.hexagons.loc[(slice(None), countries_subsample), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cities_df = z_df.reset_index(level=[0, 1, 3], drop=True).index.unique()\n",
    "print(\"Cities:\", unique_cities_df.size)\n",
    "unique_cities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = list(ds.config.featureset_selection[\"features\"].keys())\n",
    "feature_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_fs_long = features_wide_to_long(ds.edges_feature_selected.assign(geometry=ds.edges[\"geometry\"]), feature_keys)\n",
    "edges_fs_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df_profile = input_df.copy()\n",
    "for f_k in feature_keys:\n",
    "        features_for_key = [x for x in input_df.columns if f_k in x]\n",
    "        input_df_profile[features_for_key] = input_df_profile[features_for_key].apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "input_df_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hex_profile(hex_id: str) -> pd.Series:\n",
    "    hex_profile = input_df_profile.loc[(slice(None), slice(None), slice(None), hex_id)] \\\n",
    "        .iloc[0] \\\n",
    "        .sort_values(ascending=False)\n",
    "\n",
    "    return hex_profile[hex_profile > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_model = AgglomerativeClustering(n_clusters=vc.n_clusters, distance_threshold=vc.distance_threshold, affinity=vc.affinity, linkage=vc.linkage)\n",
    "ac_model.fit(z_df_scaled)\n",
    "# ac_model = AgglomerativeClustering(n_clusters=vc.n_clusters, distance_threshold=vc.distance_threshold, affinity=\"cosine\", linkage=\"average\")  # use with_std=False in StandardScaler\n",
    "# ac_model.fit(z_df_scaled_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram_path = vis_dir / \"dendrogram.png\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "plt.xlabel(\"Number of microregions\")\n",
    "\n",
    "linkage_matrix = visualize_dendrogram(ac_model, truncate_mode=vc.truncate_mode, p=vc.p, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(dendrogram_path, facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df_with_clusters = z_df.copy()\n",
    "cut_tree_results = cut_tree(linkage_matrix, n_clusters = vc.clusters)\n",
    "clusters_divided = [None]\n",
    "for index, c in tqdm(list(enumerate(vc.clusters))):\n",
    "    assigned_clusters = cut_tree_results[:, index]\n",
    "    z_df_with_clusters[f\"cluster_{c}\"] = pd.Series(assigned_clusters, index=z_df.index).astype(\"category\")\n",
    "\n",
    "    if index > 0:\n",
    "        remapped_clusters, cluster_divided_id = remap_cluster(z_df_with_clusters, c=c)\n",
    "        clusters_divided.append(cluster_divided_id)\n",
    "        z_df_with_clusters[f\"cluster_{c}\"] = remapped_clusters\n",
    "\n",
    "hexagons_clustered = hexagons.join(z_df_with_clusters[[f\"cluster_{c}\" for c in vc.clusters]]).dropna().set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters = z_df_with_clusters[[f\"cluster_{c}\" for c in vc.clusters]]\n",
    "df_clusters.to_pickle(vis_dir / \"clusters.pkl.gz\")\n",
    "\n",
    "import csv\n",
    "with open(vis_dir / \"clusters_divided.csv\", \"w\") as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(clusters_divided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_keplergl = edges_fs_long.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"edges_hexes\"\n",
    "\n",
    "hexagons_keplergl = hexagons_clustered.reset_index().drop(columns=[\"coordinates\", \"parent\", \"children\"])\n",
    "hexagons_keplergl[\"h3_id\"] = hexagons_keplergl[\"h3_id\"].map(lambda x: f\"hex_{x}\")\n",
    "\n",
    "\n",
    "m = visualize_kepler(data={\n",
    "        \"edges\": edges_keplergl,\n",
    "        \"hexagons\": hexagons_keplergl,\n",
    "    }, \n",
    "    config_name=config_name)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_config(m, config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.tools.vis_utils import save_kepler_map\n",
    "# save_kepler_map(m, config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexagons_dir = vis_dir / \"hexagons\"\n",
    "hexagons_dir.mkdir(parents=True, exist_ok=True)\n",
    "for ctp in tqdm(vc.cities_to_plot):\n",
    "    for idx, c in enumerate(vc.clusters):\n",
    "        cluster_divided_id = clusters_divided[idx]\n",
    "        ax = plot_hexagons_map(hexagons_clustered.loc[:, :, ctp], ds.edges.loc[:, :, ctp], f\"cluster_{c}\", title=f\"Division on cluster {cluster_divided_id} to {cluster_divided_id} and {c - 1}\" if cluster_divided_id is not None else \"Initial division\")\n",
    "        ax.set_axis_off()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(hexagons_dir / f\"{ctp}_cluster_{c}.png\", facecolor='w', dpi=100)\n",
    "        plt.close()\n",
    "        print(f\"Division on cluster {cluster_divided_id} to {cluster_divided_id} and {c - 1}\" if cluster_divided_id is not None else \"Initial division\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_df_tsned = reduce_tsne(z_df_scaled, n_components=vc.umap_n_components, perplexity=vc.tsne_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_dir = vis_dir / \"tsne\"\n",
    "tsne_dir.mkdir(parents=True, exist_ok=True)\n",
    "for idx, c in enumerate(vc.clusters):\n",
    "    cluster_divided_id = clusters_divided[idx]\n",
    "    cluster_to_show = f\"cluster_{c}\"\n",
    "    z_df_tsned[\"cluster\"] = z_df_with_clusters[cluster_to_show]\n",
    "    fig = plot_clusters(z_df_tsned.sort_values(\"cluster\"), title=f\"Division on cluster {cluster_divided_id} to {cluster_divided_id} and {c - 1}\" if cluster_divided_id is not None else \"Initial division\")\n",
    "    # fig = plot_clusters(z_df_tsned.sort_values(\"cluster\"), title=\"\")\n",
    "    fig.write_image(tsne_dir / f\"tsne_hexes_{c}.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_diff(z_df, hex_id_1, hex_id_2, operator_func, metric, city=None, top_n=5):\n",
    "    hex_1_z = z_df.loc[(slice(None), slice(None), slice(None), hex_id_1), :]\n",
    "    hex_2_z = z_df.loc[(slice(None), slice(None), slice(None), hex_id_2), :]\n",
    "    hex_diff_z = operator_func(hex_1_z.values, hex_2_z.values).reshape(1, -1)\n",
    "\n",
    "    if city is None:\n",
    "        df = z_df\n",
    "    else: \n",
    "        df = z_df.loc[(slice(None), slice(None), city), :]\n",
    "\n",
    "\n",
    "    hex_diff_closest_ids = pairwise_distances(df, hex_diff_z, metric=metric).argsort(axis=0)[:top_n].squeeze()\n",
    "    hex_diff_closest = df.iloc[np.array([hex_diff_closest_ids]).reshape(-1,)]\n",
    "\n",
    "    hex_1 = input_df.loc[hex_1_z.index].assign(diff=\"first\").assign(top_n=0)\n",
    "    hex_2 = input_df.loc[hex_2_z.index].assign(diff=\"second\").assign(top_n=0)\n",
    "    hex_diff = input_df.loc[hex_diff_closest.index].assign(diff=\"diff\").assign(top_n=list(range(top_n))).drop(hex_1.index, errors=\"ignore\").drop(hex_2.index, errors=\"ignore\")\n",
    "\n",
    "    diff_gdf = gpd.GeoDataFrame(pd.concat([hex_1, hex_2, hex_diff], axis=0).join(hexagons[\"geometry\"]), crs=\"EPSG:4326\")\n",
    "\n",
    "    return diff_gdf\n",
    "\n",
    "def hex_interp(z_df, hex_start_id, hex_end_id, metric, city=None, n_steps=20):\n",
    "    z_start = z_df.loc[(slice(None), slice(None), slice(None), hex_start_id), :]\n",
    "    z_end = z_df.loc[(slice(None), slice(None), slice(None), hex_end_id), :]\n",
    "    hex_start = input_df.loc[z_start.index].assign(type=\"start\").assign(step=0)\n",
    "    hex_end = input_df.loc[z_end.index].assign(type=\"end\").assign(step=0)\n",
    "\n",
    "\n",
    "    if city is None:\n",
    "        df = z_df\n",
    "    else: \n",
    "        df = z_df.loc[(slice(None), slice(None), city), :]\n",
    "    steps = np.linspace(z_start, z_end, n_steps)\n",
    "    hexes_steps = pd.DataFrame()\n",
    "    for idx, step in enumerate(steps): \n",
    "\n",
    "        hex_diff_closest_id = pairwise_distances_argmin(df, step, axis=0, metric=metric).item()\n",
    "        hex_diff_closest = df.iloc[[hex_diff_closest_id]]\n",
    "\n",
    "        \n",
    "        hex_step = input_df.loc[hex_diff_closest.index]\n",
    "        hexes_steps = pd.concat([hexes_steps, hex_step], axis=0)\n",
    "    hexes_steps = hexes_steps.drop_duplicates().drop(hex_start.index, errors=\"ignore\").drop(hex_end.index, errors=\"ignore\")\n",
    "    hexes_steps = hexes_steps.assign(type=\"diff\").assign(step=list(range(hexes_steps.shape[0])))\n",
    "\n",
    "    steps_final = pd.concat([hex_start, hexes_steps, hex_end], axis=0)\n",
    "    steps_final = features_wide_to_long(steps_final, feature_keys)\n",
    "    steps_final = gpd.GeoDataFrame(steps_final.join(hexagons[\"geometry\"]), crs=\"EPSG:4326\")\n",
    "    return steps_final\n",
    "\n",
    "\n",
    "vis_operations_dir = vis_dir / \"operations\"\n",
    "vis_operations_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hex_profile(hex_profile: pd.Series) -> plt.Axes:\n",
    "    ax = hex_profile.plot(kind=\"bar\", figsize=(8, 5))\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.xlabel(\"Tag\")\n",
    "    plt.ylabel(\"Share\")\n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "hex_profile_ids = [\"881e2055a5fffff\", \"881e2042d9fffff\"]\n",
    "for hex_profile_id in hex_profile_ids:\n",
    "    hex_profile = get_hex_profile(hex_profile_id)\n",
    "    plot_hex_profile(hex_profile)\n",
    "    plt.savefig(vis_operations_dir / f\"hex_{hex_profile_id}_profile.png\", facecolor='w')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_id_first = \"881e2055a5fffff\"\n",
    "hex_id_second = \"881e2042d9fffff\"\n",
    "operator_func = operator.add\n",
    "\n",
    "top_n = 1\n",
    "city = \"Wrocław\"\n",
    "\n",
    "diff_gdf = hex_diff(z_df_scaled_cosine, hex_id_first, hex_id_second, operator_func, metric=\"cosine\", city=city, top_n=top_n)\n",
    "# diff_gdf = hex_diff(z_df_scaled, hex_id_first, hex_id_second, operator_func, metric=\"euclidean\", city=city, top_n=top_n)\n",
    "unique_cities_in_diff = diff_gdf.index.droplevel(3).unique()\n",
    "display(unique_cities_in_diff)\n",
    "\n",
    "diff_gdf = diff_gdf.reset_index()\n",
    "diff_gdf[\"h3_id\"] = diff_gdf[\"h3_id\"].map(lambda x: f\"hex_{x}\")\n",
    "config_name = \"hex_diff\"\n",
    "m = visualize_kepler(data={\n",
    "        \"edges\": edges_keplergl.droplevel(3).loc[unique_cities_in_diff],\n",
    "        \"diff\": diff_gdf.copy(),\n",
    "    }, \n",
    "    config_name=config_name)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_config(m, config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_h3_id = \"881e2055a5fffff\"\n",
    "end_h3_id = \"881e2042d9fffff\"\n",
    "\n",
    "city = \"Wrocław\"\n",
    "n_steps = 5\n",
    "\n",
    "metric = \"euclidean\"\n",
    "df = z_df_scaled\n",
    "\n",
    "# metric = \"cosine\"\n",
    "# df = z_df_scaled_cosine\n",
    "\n",
    "steps_final = hex_interp(df, start_h3_id, end_h3_id, metric=metric, city=city, n_steps=n_steps)\n",
    "\n",
    "unique_cities_in_steps = steps_final.index.droplevel(3).unique()\n",
    "display(unique_cities_in_steps)\n",
    "display(steps_final)\n",
    "steps_final = steps_final.reset_index()\n",
    "steps_final[\"h3_id\"] = steps_final[\"h3_id\"].map(lambda x: f\"hex_{x}\")\n",
    "config_name = \"hex_interp\"\n",
    "m = visualize_kepler(data={\n",
    "        \"edges\": edges_keplergl.droplevel(3).loc[unique_cities_in_steps],\n",
    "        \"diff\": steps_final.copy(),\n",
    "    }, \n",
    "    config_name=config_name)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_config(m, config_name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_difference(df_mean, first_cluster, second_cluster):\n",
    "    return (df_mean.loc[first_cluster] - df_mean.loc[second_cluster]).sort_values(ascending=False)\n",
    "\n",
    "vis_features_dir = vis_dir / \"features\"\n",
    "\n",
    "for idx, c in tqdm(list(enumerate(vc.clusters))):\n",
    "    c_name = f\"cluster_{c}\"\n",
    "    input_df_cluster_mean = input_df_mean.groupby(df_clusters[c_name]).mean()\n",
    "\n",
    "\n",
    "    # input_df_cluster_mean_perc = input_df_cluster_mean.apply(lambda x: x / x.sum())  # or\n",
    "    input_df_cluster_mean_perc = input_df_cluster_mean.copy()\n",
    "    for f_k in feature_keys:\n",
    "        features_for_key = [x for x in input_df_cluster_mean_perc.columns if f_k in x]\n",
    "        input_df_cluster_mean_perc[features_for_key] = input_df_cluster_mean_perc[features_for_key].apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "\n",
    "    vis_features_cluster_dir = vis_features_dir / c_name\n",
    "    vis_features_cluster_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    features_wide_to_long(input_df_cluster_mean_perc, feature_keys).T.to_csv(vis_features_cluster_dir / \"clusters_characteristics.csv\")\n",
    "\n",
    "\n",
    "    cluster_divided_id = clusters_divided[idx]\n",
    "    if cluster_divided_id is None:\n",
    "        c_first = 1\n",
    "        c_second = 0\n",
    "    elif cluster_divided_id != -1:\n",
    "        c_first = c - 1\n",
    "        c_second = cluster_divided_id\n",
    "    else:\n",
    "        c_first, c_second = None, None\n",
    "\n",
    "    if c_first not in (None, -1) and c_second not in (None, -1):\n",
    "        mean_cluster_difference = cluster_difference(input_df_cluster_mean, c_first, c_second)\n",
    "        mean_cluster_difference = mean_cluster_difference[mean_cluster_difference.abs() >= 0.01]\n",
    "        mean_cluster_difference.plot(kind=\"bar\", figsize=(10, 6), color=(mean_cluster_difference >= 0).map({True: \"green\", False: \"red\"}), title=f\"Cluster difference: {c_first} - {c_second}\")\n",
    "        plt.ylabel(\"Difference in share\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(vis_features_cluster_dir / f\"cluster_difference_{c_first}-{c_second}.png\", facecolor='w')\n",
    "        plt.close()\n",
    "        print(f\"Cluster difference: {c_first} - {c_second}\")\n",
    "\n",
    "\n",
    "    for f_k in feature_keys:\n",
    "        features_for_key = [x for x in input_df_cluster_mean_perc.columns if f_k in x]\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        df = input_df_cluster_mean_perc[features_for_key]\n",
    "        df.columns = df.columns.map(lambda x: x.split(\"_\", 1)[1])\n",
    "        df.plot(kind=\"bar\", stacked=True, ax=ax, cmap=\"tab20\")\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "        plt.xlabel(\"Cluster\")\n",
    "        plt.ylabel(\"Share\")\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(vis_features_cluster_dir / f\"{f_k}.png\", facecolor='w')\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_rgb_dir = vis_dir / \"pca_rgb\"\n",
    "pca_rgb_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "z_df_rgb = pd.DataFrame(PCA(n_components=3).fit_transform(z_df)).set_index(z_df.index)\n",
    "z_df_rgb.columns = [\"r\", \"g\", \"b\"]\n",
    "z_df_rgb_scaled = pd.DataFrame(MinMaxScaler().fit_transform(z_df_rgb)).set_index(z_df.index)\n",
    "rgb_gdf = gpd.GeoDataFrame(z_df_rgb_scaled.join(hexagons[[\"geometry\"]]), crs=\"EPSG:4326\")\n",
    "for ctp in tqdm(vc.cities_to_plot):\n",
    "    fig, ax = plt.subplots(figsize=(10, 9))\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f\"{ctp} RGB\")\n",
    "    ax.set_axis_off()\n",
    "    gpd_rgb = rgb_gdf.loc[:, :, ctp]\n",
    "    gpd_rgb.to_crs(epsg=3857).plot(ax=ax, alpha=0.7, color=gpd_rgb[[0, 1, 2]].to_numpy())\n",
    "    plt.tight_layout()\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    fig.savefig(pca_rgb_dir / f\"{ctp}.png\", facecolor='w', dpi=100)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "a105a9c9c007cd582c8b6247fc84e990a9f763c9f7fefd3f75781f701789a723"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

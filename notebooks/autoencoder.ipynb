{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.settings import *\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from src.models.autoencoder import LitAutoEncoder\n",
    "import json5 as json\n",
    "import pickle as pkl\n",
    "from src.tools.configs import ExperimentConfig, DatasetGenerationConfig\n",
    "from src.tools.feature_extraction import SpatialDataset\n",
    "import dataclasses\n",
    "import gzip\n",
    "from src.tools.feature_extraction import apply_feature_selection, normalize_df\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.tools.feature_extraction import features_wide_to_long\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ExperimentConfig(\n",
    "    dataset_filename=\"dataset_2022-11-01_11-39-37.pkl.gz\",\n",
    "    model_name=\"autoencoder\",\n",
    "    mode=\"edges\",\n",
    "    # test_cities=[\"Łódź\"],\n",
    "    test_cities=[],\n",
    "    test_size = 0.2,\n",
    "    random_seed=42,\n",
    "    batch_size=200,\n",
    "    num_workers=3,\n",
    "    shuffle=True,\n",
    "    hidden_dim=64,\n",
    "    enc_out_dim=40,\n",
    "    latent_dim=30,\n",
    "    epochs=10,\n",
    "    kl_coeff=0.1,\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = FEATURES_DIR / ec.dataset_filename\n",
    "with gzip.open(ds_path, \"rb\") as f:\n",
    "    ds: SpatialDataset = pkl.load(f)\n",
    "\n",
    "ds.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = ds.config\n",
    "cities = ds.cities\n",
    "edges = ds.edges\n",
    "edges_feature_selected = ds.edges_feature_selected\n",
    "hexagons = ds.hexagons\n",
    "hex_agg = ds.hex_agg\n",
    "hex_agg_normalized = ds.hex_agg_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = ec.random_seed\n",
    "pl.seed_everything(random_seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ec.mode == \"edges\":\n",
    "    input_df = edges_feature_selected\n",
    "elif ec.mode == \"hexagons\":\n",
    "    input_df = hex_agg_normalized\n",
    "else:\n",
    "    raise ValueError(f\"Unknown mode: {ec.mode}\")\n",
    "\n",
    "test_cities = ec.test_cities\n",
    "X = torch.Tensor(input_df.values)\n",
    "if test_cities:\n",
    "    train_cities = list(set(cities[\"city\"]) - set(test_cities))\n",
    "    X_train = torch.Tensor(input_df.drop(index=test_cities, level=2).values)\n",
    "    X_test = torch.Tensor(input_df.loc[:, :, test_cities].values)\n",
    "else:\n",
    "    feature_keys = list(ds_config.featureset_selection[\"features\"].keys())\n",
    "    input_df_long = features_wide_to_long(input_df, feature_keys)\n",
    "    most_frequent_value = input_df_long[\"highway\"].value_counts().index[0]\n",
    "    X_train, X_test = train_test_split(X, test_size=ec.test_size, random_state=random_seed, shuffle=True, stratify=input_df_long[\"highway\"].fillna(most_frequent_value))\n",
    "    del input_df_long\n",
    "\n",
    "batch_size = ec.batch_size\n",
    "num_workers = ec.num_workers\n",
    "shuffle = ec.shuffle\n",
    "\n",
    "X_train_dl = DataLoader(X_train, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "X_test_dl = DataLoader(X_test, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "print(\"Number of features:\", n_features)\n",
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of test samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"run_01\"\n",
    "run_dir = RUNS_DATA_DIR / run_name\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hidden_dim = ec.hidden_dim\n",
    "enc_out_dim = ec.enc_out_dim\n",
    "latent_dim = ec.latent_dim\n",
    "epochs = ec.epochs\n",
    "kl_coeff = ec.kl_coeff\n",
    "lr = ec.lr\n",
    "\n",
    "input_path = run_dir / \"input.pkl.gz\"\n",
    "input_df.to_pickle(input_path)\n",
    "\n",
    "model = LitAutoEncoder(in_dim=n_features, hidden_dim=hidden_dim, latent_dim=latent_dim, lr=lr)\n",
    "\n",
    "trainer = pl.Trainer(gpus=0, max_epochs=epochs, default_root_dir=CHECKPOINTS_DIR, precision=16)\n",
    "trainer.fit(model, train_dataloaders=X_train_dl, val_dataloaders=X_test_dl)\n",
    "trainer.save_checkpoint(run_dir / \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z_df = pd.DataFrame(model(X).detach().numpy()).add_prefix(\"z_\")\n",
    "z_df.index = input_df.index\n",
    "\n",
    "embeddings_path = run_dir / \"embeddings.pkl.gz\"\n",
    "z_df.to_pickle(embeddings_path)\n",
    "\n",
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / \"experiment_config.json\", \"w\") as f:\n",
    "    json.dump(dataclasses.asdict(ec), f, indent=2, quote_keys=True, trailing_commas=False)\n",
    "\n",
    "with open(run_dir / \"dataset_generation_config.json\", \"w\") as f:\n",
    "    json.dump(dataclasses.asdict(ds_config), f, indent=2, quote_keys=True, trailing_commas=False)\n",
    "\n",
    "with gzip.open(run_dir / \"dataset.pkl.gz\", \"wb\") as f:\n",
    "    pkl.dump(ds, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "metadata": {
   "interpreter": {
    "hash": "d3c344be017dd5dba7ed0744b138aa90728f55fbc920f4ab22618c6bb6b41028"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "a105a9c9c007cd582c8b6247fc84e990a9f763c9f7fefd3f75781f701789a723"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

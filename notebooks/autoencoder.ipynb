{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from src.settings import *\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from src.tools.osmnx_utils import get_place_dir_name\n",
    "from src.tools.h3_utils import get_resolution_buffered_suffix, get_edges_with_features_filename\n",
    "import plotly.express as px\n",
    "from src.tools.clustering import cluster_hdbscan\n",
    "from src.models.tfidf import tfidf\n",
    "from src.tools.dim_reduction import reduce_umap\n",
    "import matplotlib.pyplot as plt\n",
    "from src.tools.aggregation import aggregate_hex\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "from src.models.autoencoder import LitAutoEncoder, LitVAE\n",
    "from src.tools.feature_extraction import apply_feature_selection, sparse_dtype, normalize_df\n",
    "import json5 as json\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from src.tools.vis_utils import plot_clusters, plot_hexagons_map, visualize_dendrogram, FIGSIZE\n",
    "import pickle as pkl\n",
    "from src.tools.configs import ExperimentConfig, DatasetGenerationConfig\n",
    "from src.tools.feature_extraction import SpatialDataset\n",
    "import dataclasses\n",
    "import gzip\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ExperimentConfig(\n",
    "    dataset_filename=\"dataset_2021-11-29_20-45-47.pkl.gz\",\n",
    "    model_name=\"autoencoder\",\n",
    "    test_cities=[\"Łódź\"],\n",
    "    random_seed=42,\n",
    "    batch_size=64,\n",
    "    num_workers=3,\n",
    "    shuffle=True,\n",
    "    hidden_dim=64,\n",
    "    enc_out_dim=40,\n",
    "    latent_dim=30,\n",
    "    epochs=10,\n",
    "    kl_coeff=0.1,\n",
    "    lr=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = FEATURES_DIR / ec.dataset_filename\n",
    "with open(ds_path, \"rb\") as f:\n",
    "    ds: SpatialDataset = pkl.load(f)\n",
    "\n",
    "ds.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_config = ds.config\n",
    "cities = ds.cities\n",
    "edges = ds.edges\n",
    "hexagons = ds.hexagons\n",
    "hex_agg = ds.hex_agg\n",
    "hex_agg_normalized = ds.hex_agg_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = ec.random_seed\n",
    "pl.seed_everything(random_seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cities = ec.test_cities\n",
    "train_cities = list(set(cities[\"city\"]) - set(test_cities))\n",
    "\n",
    "X = torch.Tensor(hex_agg_normalized.values)\n",
    "X_train = torch.Tensor(hex_agg_normalized.drop(index=test_cities, level=2).values)\n",
    "X_test = torch.Tensor(hex_agg_normalized.loc[:, :, test_cities].values)\n",
    "\n",
    "batch_size = ec.batch_size\n",
    "num_workers = ec.num_workers\n",
    "shuffle = ec.shuffle\n",
    "\n",
    "X_train_dl = DataLoader(X_train, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "X_test_dl = DataLoader(X_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(log_model=True)\n",
    "run = wandb.init(project=\"osm-road-infrastructure_autoencoder\", entity=\"pwr-spatial-lab\", dir=CHECKPOINTS_DIR, reinit=True)\n",
    "run_name = run.name\n",
    "run_dir = RUNS_DATA_DIR / run_name\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hidden_dim = ec.hidden_dim\n",
    "enc_out_dim = ec.enc_out_dim\n",
    "latent_dim = ec.latent_dim\n",
    "epochs = ec.epochs\n",
    "kl_coeff = ec.kl_coeff\n",
    "lr = ec.lr\n",
    "\n",
    "config = wandb.config\n",
    "config.experiment_config = dataclasses.asdict(ec)\n",
    "config.dataset_generation_config = dataclasses.asdict(ds.config)\n",
    "\n",
    "input_path = run_dir / \"input.pkl.gz\"\n",
    "hex_agg_normalized.to_pickle(input_path)\n",
    "\n",
    "if ec.model_name == \"autoencoder\":\n",
    "    model = LitAutoEncoder(in_dim=n_features, hidden_dim=hidden_dim, latent_dim=latent_dim, lr=lr)\n",
    "elif ec.model_name == \"vae\":\n",
    "    model = LitVAE(in_dim=n_features, hidden_dim=hidden_dim, enc_out_dim=enc_out_dim, latent_dim=latent_dim, lr=lr, kl_coeff=kl_coeff)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model name: {ec.model_name}\")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=epochs, logger=wandb_logger, default_root_dir=CHECKPOINTS_DIR)\n",
    "trainer.fit(model, train_dataloaders=X_train_dl, val_dataloaders=X_test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "z_df = pd.DataFrame(model(X).detach().numpy()).add_prefix(\"z_\")\n",
    "z_df.index = hex_agg_normalized.index\n",
    "\n",
    "embeddings_path = run_dir / \"embeddings.pkl.gz\"\n",
    "z_df.to_pickle(embeddings_path)\n",
    "\n",
    "dataset_artifact = wandb.Artifact(f\"dataset-{run_name}\", type=\"dataset\")\n",
    "dataset_artifact.add_file(input_path)\n",
    "wandb.log_artifact(dataset_artifact)\n",
    "\n",
    "result_artifact = wandb.Artifact(f\"result-{run_name}\", type=\"result\")\n",
    "result_artifact.add_file(embeddings_path)\n",
    "wandb.log_artifact(result_artifact)\n",
    "\n",
    "z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / \"experiment_config.json\", \"w\") as f:\n",
    "    json.dump(dataclasses.asdict(ec), f, indent=2, quote_keys=True, trailing_commas=False)\n",
    "\n",
    "with open(run_dir / \"dataset_generation_config.json\", \"w\") as f:\n",
    "    json.dump(dataclasses.asdict(ds_config), f, indent=2, quote_keys=True, trailing_commas=False)\n",
    "\n",
    "with gzip.open(run_dir / \"dataset.pkl.gz\", \"wb\") as f:\n",
    "    pkl.dump(ds, f)\n",
    "\n",
    "trainer.save_checkpoint(run_dir / \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3c344be017dd5dba7ed0744b138aa90728f55fbc920f4ab22618c6bb6b41028"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "d3c344be017dd5dba7ed0744b138aa90728f55fbc920f4ab22618c6bb6b41028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

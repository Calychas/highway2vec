{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm.auto import tqdm\n",
    "from src.settings import *\n",
    "from src.tools.osmnx_utils import get_place_dir_name\n",
    "import json5 as json\n",
    "from functional import seq\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RAW_DATA_DIR / \"featureset_transformation_default.jsonc\", \"r\") as f:\n",
    "    featureset = json.load(f)\n",
    "    features = list(featureset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>kacper</th>\n",
       "      <th>szymon</th>\n",
       "      <th>piotr</th>\n",
       "      <th>kamil</th>\n",
       "      <th>regions</th>\n",
       "      <th>to_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Wrocław</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city country continent  kacper  szymon  piotr  kamil regions  to_fix\n",
       "85  Wrocław  Poland    Europe    True    True   True   True     NaN   False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = pd.read_csv(RAW_DATA_DIR / \"cities.csv\")\n",
    "# cities = cities[(cities.kacper)]\n",
    "# cities = cities[(cities[\"country\"] == \"Poland\")]\n",
    "# cities = cities[(cities[\"city\"] == \"Wrocław\")]\n",
    "\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wrocław,Poland: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "network_type = \"drive\"\n",
    "\n",
    "pbar = tqdm(cities.itertuples(), total=cities.shape[0])\n",
    "edges_cities = []\n",
    "for row in pbar:\n",
    "    place_name = f\"{row.city},{row.country}\"\n",
    "    place_dir_name = get_place_dir_name(place_name)\n",
    "    pbar.set_description(place_name)\n",
    "\n",
    "    try:\n",
    "        edges_city = gpd.read_file(GENERATED_DATA_DIR / place_dir_name / f\"graph_{network_type}.gpkg\", layer=\"edges\")\n",
    "        edges_city[\"city\"] = row.city\n",
    "        edges_city[\"country\"] = row.country\n",
    "        edges_city[\"continent\"] = row.continent\n",
    "        edges_cities.append(edges_city)\n",
    "    except Exception as e:\n",
    "        print(\"\\nFailed\", place_name, e)\n",
    "    \n",
    "columns_superset = seq(edges_cities).map(lambda edges_city: set(edges_city.columns)).reduce(lambda a, b: a.union(b))\n",
    "columns_superset\n",
    "\n",
    "for edges_city in edges_cities:\n",
    "    edges_city_cols = set(edges_city.columns)\n",
    "    missing_columns = list(columns_superset - edges_city_cols)\n",
    "    edges_city[missing_columns] = None\n",
    "\n",
    "edges = pd.concat(edges_cities, ignore_index=True)\n",
    "del edges_city, edges_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 9732 entries, 0 to 9731\n",
      "Data columns (total 25 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   u          9732 non-null   int64   \n",
      " 1   v          9732 non-null   int64   \n",
      " 2   key        9732 non-null   int64   \n",
      " 3   osmid      9732 non-null   object  \n",
      " 4   oneway     9732 non-null   bool    \n",
      " 5   lanes      9732 non-null   object  \n",
      " 6   name       9732 non-null   object  \n",
      " 7   highway    9732 non-null   object  \n",
      " 8   maxspeed   9732 non-null   object  \n",
      " 9   surface    9732 non-null   object  \n",
      " 10  lit        9732 non-null   object  \n",
      " 11  length     9732 non-null   float64 \n",
      " 12  from       9732 non-null   int64   \n",
      " 13  to         9732 non-null   int64   \n",
      " 14  ref        9732 non-null   object  \n",
      " 15  bridge     9732 non-null   object  \n",
      " 16  access     9732 non-null   object  \n",
      " 17  bicycle    9732 non-null   object  \n",
      " 18  junction   9732 non-null   object  \n",
      " 19  width      9732 non-null   object  \n",
      " 20  tunnel     9732 non-null   object  \n",
      " 21  geometry   9732 non-null   geometry\n",
      " 22  city       9732 non-null   object  \n",
      " 23  country    9732 non-null   object  \n",
      " 24  continent  9732 non-null   object  \n",
      "dtypes: bool(1), float64(1), geometry(1), int64(5), object(17)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "edges.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['u', 'v', 'key', 'osmid', 'oneway', 'lanes', 'name', 'highway',\n",
       "       'maxspeed', 'surface', 'lit', 'length', 'from', 'to', 'ref', 'bridge',\n",
       "       'access', 'bicycle', 'junction', 'width', 'tunnel', 'geometry', 'city',\n",
       "       'country', 'continent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bridge: 100%|██████████| 13/13 [00:01<00:00, 11.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from src.tools.feature_extraction import sanitize, normalize, sanitize_and_normalize\n",
    "from IPython.display import clear_output\n",
    "cols_bloat = set(['u', 'v', 'geometry', 'osmid', 'from', 'to', 'ref', 'name', 'key', 'city', 'country', 'continent'])\n",
    "\n",
    "path = RAW_DATA_DIR / \"features_counts\"\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "pbar = tqdm((set(columns_superset) - cols_bloat))\n",
    "for f in pbar:\n",
    "    pbar.set_description(f)\n",
    "\n",
    "    edges_list = edges[f].apply(lambda x: eval(str(x)) if \"[\" in str(x) else [str(x)])\n",
    "    sanitized = edges_list.apply(lambda x: [sanitize(y, f) for y in x])\n",
    "    normalized = sanitized.apply(lambda x: [normalize(y, f) for y in x])\n",
    "\n",
    "    counts = edges_list.explode().value_counts().sort_values(ascending=False)\n",
    "    counts_sanitized = sanitized.explode().value_counts().sort_values(ascending=False)\n",
    "    counts_normalized = normalized.explode().value_counts().sort_values(ascending=False)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    # edges_list.to_csv(path / f\"{f}.csv\")\n",
    "    # sanitized.to_csv(path / f\"{f}_sanitized.csv\")\n",
    "    # normalized.to_csv(path / f\"{f}_normalized.csv\")\n",
    "\n",
    "    counts.to_csv(path / f\"{f}_counts.csv\")\n",
    "    counts_sanitized.to_csv(path / f\"{f}_sanitized_counts.csv\")\n",
    "    counts_normalized.to_csv(path / f\"{f}_normalized_counts.csv\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d3c344be017dd5dba7ed0744b138aa90728f55fbc920f4ab22618c6bb6b41028"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
